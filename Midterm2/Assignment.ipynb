{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm 2 Assignment 3 Davide Amadei"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Iterator\n",
    "import time\n",
    "from sewar.full_ref import uqi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(image: np.ndarray, gray: bool = True, title: str = None) -> None:\n",
    "    \"\"\"simple utility to show images with axes disabled\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        image to show\n",
    "    gray : bool, optional\n",
    "        if true show image in grayscale, by default True\n",
    "    \"\"\"\n",
    "    if gray:\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Mean Squared Error\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        first input\n",
    "    y : np.ndarray\n",
    "        second input\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        returns the Mean Squared Error computed on x and y\n",
    "    \"\"\"\n",
    "    return ((x-y)**2).mean()\n",
    "\n",
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"sigmoid function applied elementwise to a matrix or vector\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        input matrix or vector\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        matrix or vector of same size of input containing elementwise sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read MNIST dataset\n",
    "As the MNIST dataset is provided in idx format it has to be read from the original file to be converted into a usable form.<br>\n",
    "This function does exactly that, decoding the file based on the format explained on the MNIST site http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_MNIST_file(path: str, reshape: bool = False) -> tuple[tuple, np.ndarray]:\n",
    "    \"\"\"simple utility function to read a file containing MNIST datasets and labels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path containing the file to load\n",
    "    reshape : bool, optional\n",
    "        flag determining wheter the dataset is returned already reshaped as images or flattened.\n",
    "        If True each element of the dataset is reshaped to a matrix of size 28x28, \n",
    "        else each element is a vector of size 784, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[tuple, np.ndarray]\n",
    "        the shape of the output data and either the dataset or the labels read from the file\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        if the magic numbers of the file are wrong\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        magic = int.from_bytes(f.read(4))\n",
    "        n_items = int.from_bytes(f.read(4))\n",
    "\n",
    "        # image file\n",
    "        if magic == 2051:\n",
    "            n_rows = int.from_bytes(f.read(4))\n",
    "            n_columns = int.from_bytes(f.read(4))\n",
    "\n",
    "            # if reshape is true change the output shape\n",
    "            if reshape:\n",
    "                shape = (n_items, n_rows, n_columns)\n",
    "            else:\n",
    "                shape = (n_items, n_rows * n_columns)\n",
    "            images = np.ndarray(shape)\n",
    "\n",
    "            # read each image one by one\n",
    "            for i in range(n_items):\n",
    "                img_buffer = f.read(n_rows*n_columns)\n",
    "                # convert binary data buffer to numpy int array\n",
    "                img = np.frombuffer(img_buffer, np.uint8)\n",
    "\n",
    "                # reshape the image if needed\n",
    "                if reshape:\n",
    "                    img = np.reshape(img, (n_rows, n_columns))\n",
    "\n",
    "                images[i] = img\n",
    "            # the images are returned already normalized between 0 and 1,\n",
    "            # necessary for data to be usable\n",
    "            return (shape, images/255)\n",
    "        # label file\n",
    "        elif magic == 2049:\n",
    "            label_buffer = f.read(n_items)\n",
    "            # convert binary data buffer to numpy int array\n",
    "            labels = np.frombuffer(label_buffer, np.uint8)\n",
    "            return (labels.shape, labels)\n",
    "        # wrong type of file\n",
    "        else:\n",
    "            raise ValueError(\"wrong file format\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training set and the test set with its labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_img_shape, tr_images = read_MNIST_file(\"./data/train-images-idx3-ubyte\")\n",
    "ts_img_shape, ts_images = read_MNIST_file(\"./data/t10k-images-idx3-ubyte\")\n",
    "_, test_labels = read_MNIST_file(\"./data/t10k-labels-idx1-ubyte\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machine implementation\n",
    "This is the implementation of the Restricted Boltzmann Machine and all the needed methods to train it and to use it for reconstructing data outside of the training set.<br>\n",
    "All the sampling is done binarizing the data as seen in the code example in class. This means starting from an array of elements $0 \\leq x \\leq 1$  $\\forall x$ and using them as probablities to get a binary array where each $x$ is used as the probabliity of being sampled to 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative measures for the error\n",
    "\n",
    "To get a quantitive measure of the error of the RBM during training and on the test data two measures are used. The first one is simply the MSE, compute for each batch and then averaged at the end of the epoch. The other measure is the Universal image Quality Index (UQI). It always returns a value between -1 and 1, with 1 being that the two images are the same. The implementation in the sewar library was used https://github.com/andrewekhalel/sewar. More on this index can be found on the paper it was introduced in https://ieeexplore.ieee.org/document/995823. I decided to use this in addition to MSE to get a possibly easier to interpret score of the similarity between the original image and the one reconstructed by the RBM.<br>\n",
    "Unfortunately this measure needs to be computed on each image separately, which also need to be reshaped for the UQI to work. This takes a lot of time overall and slows down the training tremendously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    \"\"\"\n",
    "    class implementing a Restricted Boltzmann Machine with a method to fit it on given data \n",
    "    and a method to reconstruct data given in input\n",
    "    \"\"\"\n",
    "    def __init__(self, v_units: int, h_units:int = 100, seed:int = None):\n",
    "        \"\"\"init method\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        v_units : int\n",
    "            number of visible units, must be the same as the size of a single element of training data\n",
    "        h_units : int\n",
    "            number of hidden units, by default 100\n",
    "        seed : int, optional\n",
    "            seed to initialize RNG, by default None\n",
    "        \"\"\"\n",
    "        self._rng = np.random.default_rng(seed)\n",
    "        self._seed = seed\n",
    "        self._weights = self._rng.normal(size=(v_units, h_units))\n",
    "        self._bv = self._rng.normal(size=v_units)\n",
    "        self._bh = self._rng.normal(size=h_units)\n",
    "        # self._bv = self._rng.uniform(0, 1, size=v_units)\n",
    "        # self._bh = self._rng.uniform(0, 1, size=h_units)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_minibatches(\n",
    "        x: np.ndarray, batchsize: int\n",
    "    ) -> Iterator[tuple[np.ndarray, np.ndarray]]:\n",
    "        \"\"\"Returns minibatches of given size over (x, y).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            data array\n",
    "        batchsize : int\n",
    "            batch size of yielded minibatches\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        Iterator[tuple[np.ndarray,np.ndarray]]\n",
    "            iterator over minibatches\n",
    "        \"\"\"\n",
    "        if batchsize in [None, 0, -1]:\n",
    "            batchsize = x.shape[0]\n",
    "        size = x.shape[0]\n",
    "        batchtotal, remainder = divmod(size, batchsize)\n",
    "        for i in range(batchtotal):\n",
    "            mini_x = x[i * batchsize : (i + 1) * batchsize]\n",
    "            yield mini_x\n",
    "        if remainder > 0:\n",
    "            yield (x[batchtotal * batchsize :])\n",
    "\n",
    "    def sample_data(self, data: np.ndarray, seed: int = None) -> np.ndarray:\n",
    "        \"\"\"method to get a sample of binary data from a given array of elements x where 0 <= x <= 1.\n",
    "        These elements are seen as probabilities and become 0 or 1 indipendently of each other.\n",
    "        P(x->1) = x, P(x->0) = 1-x \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            data to sample\n",
    "        seed : int, optional\n",
    "            seed to use for sampling, if None uses the RNG of the current obect, by default None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            an array containing the sampled data. The elements of this array are either 0 or 1\n",
    "        \"\"\"\n",
    "        if seed is None:\n",
    "            return self._rng.binomial(1, p=data)\n",
    "        else:\n",
    "            tmp_rng = np.random.default_rng(seed)\n",
    "            return tmp_rng.binomial(1, p=data)\n",
    "        \n",
    "    def reset(self, seed: int = None):\n",
    "        \"\"\"method to reset the RBM object by reinitializing weights and RNG\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int, optional\n",
    "            seed to use for RNG reinitialization. If none uses old seed, by default None\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            self._seed = seed\n",
    "        self._rng = np.random.default_rng(self._seed)\n",
    "        self._weights = self._rng.normal(size=self._weights.shape)\n",
    "        self._bv = self._rng.normal(size=self._bv.shape)\n",
    "        self._bh = self._rng.normal(size=self._bh.shape)\n",
    "        \n",
    "    def fit(self, tr_data: np.ndarray, max_epochs=10, lr: float = 1, batchsize=128, img_shape: tuple = None):\n",
    "        \"\"\"function to train the RBM\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tr_data : np.ndarray\n",
    "            data to use for training\n",
    "        max_epochs : int, optional\n",
    "            max number of epochs, by default 10\n",
    "        lr : float, optional\n",
    "            learning rate, multiplies the updates to the weights, by default 1\n",
    "        batchsize : int, optional\n",
    "            size of each batch, by default 128\n",
    "        img_shape : tuple, optional\n",
    "            shape of the images that are being processed during training.\n",
    "            If not None in addition to the MSE the Universal image Quality Index (UQI) is also computed, by default None\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "\n",
    "        # keep track of the total time spent on UQI computation\n",
    "        tot_uqi_time = 0\n",
    "\n",
    "        for i in range(max_epochs):\n",
    "            # shuffle data for the current epoch\n",
    "            shuffled_data = tr_data[self._rng.permutation(tr_data.shape[0])]\n",
    "\n",
    "            loss_list = []\n",
    "\n",
    "            # if image shape is passed UQI score is also computed\n",
    "            if img_shape is not None:\n",
    "                uqi_loss_list = []\n",
    "                epoch_uqi_time = 0\n",
    "\n",
    "            # iterate on batches\n",
    "            for batch in RBM.get_minibatches(shuffled_data, batchsize):\n",
    "                \n",
    "                # sample the training data of the current batch\n",
    "                sampled_data = self.sample_data(batch)\n",
    "                # p(h0 | v0)\n",
    "                h_prob0 = sigmoid(np.dot(sampled_data, self._weights) + self._bh)\n",
    "                # sample the output of the hidden units from p(h0 | v0)\n",
    "                sampled_h0 = self.sample_data(h_prob0)\n",
    "\n",
    "                # wake part of the weight update\n",
    "                wake = np.dot(sampled_data.T, h_prob0)\n",
    "\n",
    "                # p(v1 | h0)\n",
    "                recon_data_prob = sigmoid(np.dot(sampled_h0, self._weights.T) + self._bv)\n",
    "                # sample the reconstructed data from p(v1 | h0)\n",
    "                recon_data = self.sample_data(recon_data_prob)\n",
    "\n",
    "                # p(h1 | v1)\n",
    "                h_prob1 = sigmoid(np.dot(recon_data, self._weights) + self._bh)\n",
    "                # sampled_h1 = self.sample_data(h_prob1)\n",
    "                \n",
    "                #dream part of the weight update\n",
    "                dream = np.dot(recon_data.T, h_prob1)\n",
    "\n",
    "                # update weights\n",
    "                self._weights += lr * (wake - dream)/batch.shape[0]\n",
    "                self._bv += lr * (np.sum(sampled_data, axis=0) - \n",
    "                                  np.sum(recon_data, axis=0))/batch.shape[0]\n",
    "                self._bh += lr * (np.sum(h_prob0, axis=0) - \n",
    "                                  np.sum(h_prob1, axis=0))/batch.shape[0]\n",
    "                \n",
    "                # compute UQI score and keep track of time spent on its computation\n",
    "                if img_shape != None:\n",
    "                    uqi_time_start = time.time()\n",
    "                    uqi_loss_batch = 0\n",
    "                    # reshape the data to compute UQI\n",
    "                    reshaped_batch = np.reshape(batch, (batch.shape[0],) + img_shape)\n",
    "                    reshaped_recon_data = np.reshape(recon_data_prob, (recon_data_prob.shape[0],) + img_shape)\n",
    "\n",
    "                    # compute UQI for each image\n",
    "                    for t in range(batch.shape[0]):\n",
    "                        uqi_loss_batch += uqi(reshaped_batch[t], reshaped_recon_data[t])\n",
    "\n",
    "                    # track average UQI of current batch\n",
    "                    uqi_loss_list.append(uqi_loss_batch / batch.shape[0])\n",
    "                    uqi_time_end = time.time()\n",
    "                    epoch_uqi_time += uqi_time_end - uqi_time_start\n",
    "                \n",
    "                # track MSE for current batch\n",
    "                loss_list.append(mse(batch, recon_data_prob))\n",
    "\n",
    "            # compute average MSE and std across batches\n",
    "            loss_avg = np.round(np.mean(loss_list), 4)\n",
    "            loss_std = np.round(np.std(loss_list), 4)\n",
    "            \n",
    "            if img_shape is not None:\n",
    "                # compute average UQI and std across batches\n",
    "                uqi_loss_avg = np.round(np.mean(uqi_loss_list), 4)\n",
    "                uqi_loss_std = np.round(np.std(uqi_loss_list), 4)\n",
    "                tot_uqi_time += epoch_uqi_time\n",
    "                \n",
    "            end = time.time()\n",
    "            eta = (end - start) * (max_epochs - i - 1) / (i + 1)\n",
    "\n",
    "            # print info about current epoch\n",
    "            if img_shape is not None:\n",
    "                print(f\"Time spent on UQI computation: {np.round(epoch_uqi_time, 2)}s\")\n",
    "                print(f\"Epoch number {i+1} done. MSE: {loss_avg} \\xB1 {loss_std}. \"\n",
    "                    f\"UQI: {uqi_loss_avg} \\xB1 {uqi_loss_std} \"\n",
    "                    f\"Elapsed time: {np.round(end-start, 2)}s. ETA: {np.round(eta, 2)}s\")\n",
    "            else:\n",
    "                print(f\"Epoch number {i+1} done. MSE: {loss_avg} \\xB1 {loss_std}. \"\n",
    "                    f\"Elapsed time: {np.round(end-start, 2)}s. ETA: {np.round(eta, 2)}s\")\n",
    "        if img_shape is not None:\n",
    "            print(f\"Total time spent on UQI computation: {np.round(tot_uqi_time, 2)}s\")\n",
    "    \n",
    "    def reconstruct(self, ts_data: np.ndarray, seed:int = None) -> np.ndarray:\n",
    "        \"\"\"function to reconstruct the given input data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ts_data : np.ndarray\n",
    "            data to reconstruct\n",
    "        seed : int, optional\n",
    "            seed to use during sampling. If None uses the RNG of the RBM, by default None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            the data reconstructed by the RBM\n",
    "        \"\"\"\n",
    "        # sample the input data\n",
    "        sampled_data = self.sample_data(ts_data, seed=seed)\n",
    "\n",
    "        # p(h0 | v0)\n",
    "        h_prob0 = sigmoid(np.dot(sampled_data, self._weights) + self._bh)\n",
    "        # sample hidden units\n",
    "        sampled_h0 = self.sample_data(h_prob0, seed=seed)\n",
    "        \n",
    "        # p(v1 | h0)\n",
    "        recon_data_prob = sigmoid(np.dot(sampled_h0, self._weights.T) + self._bv)\n",
    "        return recon_data_prob\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments and results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the RBM. The visible units are 784 (28*28), which means one unit for each pixel of an image. The hidden units are 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boltzmann_machine = RBM(v_units = tr_img_shape[1], h_units = 100, seed = 123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the RBM for 20 epochs, with a learning rate of 1, batchsize equal to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boltzmann_machine.reset()\n",
    "boltzmann_machine.fit(tr_images, max_epochs = 20, lr = 1, batchsize = 50, img_shape = (28,28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct the test set on the trained RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_test = boltzmann_machine.reconstruct(ts_images)\n",
    "reconstructed_test_reshaped = np.reshape(reconstructed_test, (reconstructed_test.shape[0], 28, 28))\n",
    "ts_images_reshaped = np.reshape(ts_images, (ts_images.shape[0], 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute MSE and average UQI between original test data and reconstucted data. Notice that, while the averages are close to the ones on the training set at the end of training, the standard deviations are higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_avg = np.round(mse(ts_images, reconstructed_test), 4)\n",
    "loss_std = np.round(((ts_images - reconstructed_test)**2).std(), 4)\n",
    "uqi_loss_list = []\n",
    "\n",
    "for i in range(ts_images_reshaped.shape[0]):\n",
    "    uqi_loss_list.append(uqi(ts_images_reshaped[i], reconstructed_test_reshaped[i]))\n",
    "uqi_loss_avg = np.round(np.mean(uqi_loss_list), 4)\n",
    "uqi_loss_std = np.round(np.std(uqi_loss_list), 4)\n",
    "\n",
    "print(f\"MSE: {loss_avg} \\xB1 {loss_std}\\n\"\n",
    "      f\"UQI: {uqi_loss_avg} \\xB1 {uqi_loss_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = boltzmann_machine._weights.T\n",
    "weights = np.reshape(weights, (weights.shape[0], 28, 28))\n",
    "\n",
    "n_rows = 10\n",
    "n_columns = 10\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_columns, figsize=(10, 10))\n",
    "\n",
    "i = 0\n",
    "for row in range(n_rows):\n",
    "    for column in range(n_columns):\n",
    "        ax = axes[row, column]\n",
    "        ax.axis(\"off\")\n",
    "        ax.imshow(weights[i], cmap=\"gray\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    indices = np.where(test_labels==i)[0]\n",
    "    loss_avg = mse(ts_images[indices], reconstructed_test[indices])\n",
    "    uqi_avg = 0\n",
    "    for index in indices:\n",
    "        uqi_avg += uqi(ts_images_reshaped[index], reconstructed_test_reshaped[index])\n",
    "    uqi_avg /= indices.shape[0]\n",
    "    print(f\"Digit: {i}. Average MSE: {np.round(loss_avg, 4)}. Average UQI: {np.round(uqi_avg, 4)}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of the images reconstructed by the RBM, one for each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [10, 5, 1, 30, 4, 2798, 1831, 0, 61, 9]\n",
    "n_rows = 2\n",
    "n_columns = 10\n",
    "fig, axes = plt.subplots(n_rows, n_columns, figsize=(15, 3))\n",
    "\n",
    "for column in range(n_columns):\n",
    "    ax = axes[0, column]\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"UQI: {np.round(uqi(ts_images_reshaped[column], reconstructed_test_reshaped[column]), 2)}\")\n",
    "    ax.imshow(ts_images_reshaped[indices[column]], cmap=\"gray\")\n",
    "    ax = axes[1, column]\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"MSE: {np.round(mse(ts_images_reshaped[column], reconstructed_test_reshaped[column]), 3)}\")\n",
    "    ax.imshow(reconstructed_test_reshaped[indices[column]], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2983\n",
    "print(uqi(ts_images_reshaped[index], reconstructed_test_reshaped[index]))\n",
    "show_img(ts_images_reshaped[index])\n",
    "show_img(reconstructed_test_reshaped[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISPR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bb2bfd8162fb1fc2ac60c00546b252b3b1ae7a878ee25718b25f318c3edd43c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
