{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm 2 Assignment 3 Davide Amadei"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Iterator\n",
    "import time\n",
    "from sewar.full_ref import uqi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(image: np.ndarray, gray: bool = True, title: str = None) -> None:\n",
    "    \"\"\"simple utility to show images with axes disabled\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        image to show\n",
    "    gray : bool, optional\n",
    "        if true show image in grayscale, by default True\n",
    "    \"\"\"\n",
    "    if gray:\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Mean Squared Error\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        first input\n",
    "    y : np.ndarray\n",
    "        second input\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        returns the Mean Squared Error computed on x and y\n",
    "    \"\"\"\n",
    "    return ((x-y)**2).mean()\n",
    "\n",
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"sigmoid function applied elementwise to a matrix or vector\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        input matrix or vector\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        matrix or vector of same size of input containing elementwise sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read MNIST dataset\n",
    "As the MNIST dataset is provided in idx format it has to be read from the original file to be converted into a usable form.<br>\n",
    "This function does exactly that, decoding the file based on the format explained on the MNIST site http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_MNIST_file(path: str, reshape: bool = False) -> tuple[np._ShapeType, np.ndarray]:\n",
    "    \"\"\"simple utility function to read a file containing MNIST datasets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path containing the file to load\n",
    "    reshape : bool, optional\n",
    "        flag determining wheter the dataset is returned already reshaped as images or flattened.\n",
    "        If True each element of the dataset is reshaped to a matrix of size 28x28, \n",
    "        else each element is a vector of size 784, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[np._ShapeType, np.ndarray]\n",
    "        the shape of the output data and the dataset loaded from the file\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        if the magic numbers of the file are wrong\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        magic = int.from_bytes(f.read(4))\n",
    "        n_items = int.from_bytes(f.read(4))\n",
    "\n",
    "        # image file\n",
    "        if magic == 2051:\n",
    "            n_rows = int.from_bytes(f.read(4))\n",
    "            n_columns = int.from_bytes(f.read(4))\n",
    "\n",
    "            # if reshape is true change the output shape\n",
    "            if reshape:\n",
    "                shape = (n_items, n_rows, n_columns)\n",
    "            else:\n",
    "                shape = (n_items, n_rows * n_columns)\n",
    "            images = np.ndarray(shape)\n",
    "\n",
    "            # read each image one by one\n",
    "            for i in range(n_items):\n",
    "                img_buffer = f.read(n_rows*n_columns)\n",
    "                # convert binary data buffer to numpy int array\n",
    "                img = np.frombuffer(img_buffer, np.uint8)\n",
    "\n",
    "                # reshape the image if needed\n",
    "                if reshape:\n",
    "                    img = np.reshape(img, (n_rows, n_columns))\n",
    "\n",
    "                images[i] = img\n",
    "            return (shape, images/255)\n",
    "        # label file, not implemented as it was not needed for this assignment\n",
    "        elif magic == 2049:\n",
    "            pass\n",
    "        # wrong type of file\n",
    "        else:\n",
    "            raise ValueError(\"wrong file format\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_img_shape, tr_images = read_MNIST_file(\"./data/train-images-idx3-ubyte\")\n",
    "ts_img_shape, ts_images = read_MNIST_file(\"./data/t10k-images-idx3-ubyte\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machine implementation\n",
    "This is the implementation of the Restricted Boltzmann Machine and all the needed methods to train it and to use it for reconstructing data outside of the training set.<br>\n",
    "All the sampling is done binarizing the data as seen in the code example in class. This means starting from an array of elements $0 \\leq x \\leq 1$  $\\forall x$ and using them as probablities to get a binary array where each $x$ is used as the probabliity of being sampled to 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative measures for the error\n",
    "\n",
    "To get a quantitive measure of the error of the RBM during training and on the test data two measures are used. The first one is simply the MSE, compute for each batch and then averaged at the end of the epoch. The other measure is the Universal image Quality Index (UQI). It always returns a value between 0 and 1, with 1 being that the two images are the same. The implementation in the sewar library was used https://github.com/andrewekhalel/sewar. More on this index can be found on the paper it was introduced in https://ieeexplore.ieee.org/document/995823. I decided to use this in addition to MSE to get a possibly easier to interpret score of the similarity between the original image and the one reconstructed by the RBM.<br>\n",
    "Unfortunately because of the way the UQI works and maybe because of how it is implemented in sewar it needs to be computed on each image separately, which also need to be reshaped for the UQI to work. This takes a lot of time overall and slows down the training tremendously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    \"\"\"\n",
    "    class implementing a Restricted Boltzmann Machine with a method to fit it on given data \n",
    "    and a method to reconstruct data given in input\n",
    "    \"\"\"\n",
    "    def __init__(self, v_units: int, h_units:int = 100, seed:int = None):\n",
    "        \"\"\"init method\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        v_units : int\n",
    "            number of visible units, must be the same as the size of a single element of training data\n",
    "        h_units : int\n",
    "            number of hidden units, by default 100\n",
    "        seed : int, optional\n",
    "            seed to initialize RNG, by default None\n",
    "        \"\"\"\n",
    "        self._rng = np.random.default_rng(seed)\n",
    "        self._seed = seed\n",
    "        self._weights = self._rng.normal(size=(v_units, h_units))\n",
    "        self._bv = self._rng.normal(size=v_units)\n",
    "        self._bh = self._rng.normal(size=h_units)\n",
    "        # self._bv = self._rng.uniform(0, 1, size=v_units)\n",
    "        # self._bh = self._rng.uniform(0, 1, size=h_units)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_minibatches(\n",
    "        x: np.ndarray, batchsize: int\n",
    "    ) -> Iterator[tuple[np.ndarray, np.ndarray]]:\n",
    "        \"\"\"Returns minibatches of given size over (x, y).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            data array\n",
    "        batchsize : int\n",
    "            batch size of yielded minibatches\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        Iterator[tuple[np.ndarray,np.ndarray]]\n",
    "            iterator over minibatches\n",
    "        \"\"\"\n",
    "        if batchsize in [None, 0, -1]:\n",
    "            batchsize = x.shape[0]\n",
    "        size = x.shape[0]\n",
    "        batchtotal, remainder = divmod(size, batchsize)\n",
    "        for i in range(batchtotal):\n",
    "            mini_x = x[i * batchsize : (i + 1) * batchsize]\n",
    "            yield mini_x\n",
    "        if remainder > 0:\n",
    "            yield (x[batchtotal * batchsize :])\n",
    "\n",
    "    def sample_data(self, data: np.ndarray, seed: int = None) -> np.ndarray:\n",
    "        \"\"\"method to get a sample of binary data from a given array of elements x where 0 <= x <= 1.\n",
    "        These elements are seen as probabilities and become 0 or 1 indipendently of each other.\n",
    "        P(x->1) = x, P(x->0) = 1-x \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            data to sample\n",
    "        seed : int, optional\n",
    "            seed to use for sampling, if None uses the RNG of the current obect, by default None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            an array containing the sampled data. The elements of this array are either 0 or 1\n",
    "        \"\"\"\n",
    "        if seed is None:\n",
    "            return self._rng.binomial(1, p=data)\n",
    "        else:\n",
    "            tmp_rng = np.random.default_rng(seed)\n",
    "            return tmp_rng.binomial(1, p=data)\n",
    "        \n",
    "    def reset(self, seed: int = None):\n",
    "        \"\"\"method to reset the RBM object by reinitializing weights and RNG\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int, optional\n",
    "            seed to use for RNG reinitialization. If none uses old seed, by default None\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            self._seed = seed\n",
    "        self._rng = np.random.default_rng(self._seed)\n",
    "        self._weights = self._rng.normal(size=self._weights.shape)\n",
    "        self._bv = self._rng.normal(size=self._bv.shape)\n",
    "        self._bh = self._rng.normal(size=self._bh.shape)\n",
    "        \n",
    "    def fit(self, tr_data: np.ndarray, max_epochs=10, lr: float = 1, batchsize=128, img_shape: np._ShapeType = None):\n",
    "        \"\"\"function to train the RBM\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tr_data : np.ndarray\n",
    "            data to use for training\n",
    "        max_epochs : int, optional\n",
    "            max number of epochs, by default 10\n",
    "        lr : float, optional\n",
    "            learning rate, multiplies the updates to the weights, by default 1\n",
    "        batchsize : int, optional\n",
    "            size of each batch, by default 128\n",
    "        img_shape : np._ShapeType, optional\n",
    "            shape of the images that are being processed during training.\n",
    "            If not None in addition to the MSE the Universal image Quality Index (UQI) is also computed, by default None\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "\n",
    "        # keep track of the total time spent on UQI computation\n",
    "        tot_uqi_time = 0\n",
    "\n",
    "        for i in range(max_epochs):\n",
    "            shuffled_data = tr_data[self._rng.permutation(tr_data.shape[0])]\n",
    "            loss_list = []\n",
    "            if img_shape is not None:\n",
    "                uqi_loss_list = []\n",
    "                epoch_uqi_time = 0\n",
    "            for batch in RBM.get_minibatches(shuffled_data, batchsize):\n",
    "                \n",
    "                sampled_data = self.sample_data(batch)\n",
    "                h_prob0 = sigmoid(np.dot(sampled_data, self._weights) + self._bh)\n",
    "                sampled_h0 = self.sample_data(h_prob0)\n",
    "\n",
    "                wake = np.dot(sampled_data.T, sampled_h0)\n",
    "\n",
    "                recon_data_prob = sigmoid(np.dot(sampled_h0, self._weights.T) + self._bv)\n",
    "                recon_data = self.sample_data(recon_data_prob)\n",
    "\n",
    "                h_prob1 = sigmoid(np.dot(recon_data, self._weights) + self._bh)\n",
    "                # sampled_h1 = self.sample_data(h_prob1)\n",
    "                \n",
    "                dream = np.dot(recon_data.T, h_prob1)\n",
    "\n",
    "                self._weights += lr * (wake - dream)/batch.shape[0]\n",
    "                self._bv += lr * (np.sum(sampled_data, axis=0) - \n",
    "                                  np.sum(recon_data, axis=0))/batch.shape[0]\n",
    "                self._bh += lr * (np.sum(h_prob0, axis=0) - \n",
    "                                  np.sum(h_prob1, axis=0))/batch.shape[0]\n",
    "                if img_shape != None:\n",
    "                    uqi_time_start = time.time()\n",
    "                    uqi_loss_batch = 0\n",
    "                    reshaped_batch = np.reshape(batch, (batch.shape[0],) + img_shape)\n",
    "                    reshaped_recon_data = np.reshape(recon_data_prob, (recon_data_prob.shape[0],) + img_shape)\n",
    "\n",
    "                    for t in range(batch.shape[0]):\n",
    "                        uqi_loss_batch += uqi(reshaped_batch[t], reshaped_recon_data[t])\n",
    "\n",
    "                    uqi_loss_list.append(uqi_loss_batch / batch.shape[0])\n",
    "                    uqi_time_end = time.time()\n",
    "                    epoch_uqi_time += uqi_time_end - uqi_time_start\n",
    "\n",
    "                loss_list.append(mse(batch, recon_data_prob))\n",
    "\n",
    "            loss_avg = np.round(np.mean(loss_list), 4)\n",
    "            loss_std = np.round(np.std(loss_list), 4)\n",
    "            \n",
    "            if img_shape is not None:\n",
    "                uqi_loss_avg = np.round(np.mean(uqi_loss_list), 4)\n",
    "                uqi_loss_std = np.round(np.std(uqi_loss_list), 4)\n",
    "                tot_uqi_time += epoch_uqi_time\n",
    "                \n",
    "            end = time.time()\n",
    "            eta = (end - start) * (max_epochs - i - 1) / (i + 1)\n",
    "            if img_shape is not None:\n",
    "                print(f\"Time spent on UQI computation: {np.round(epoch_uqi_time, 2)}s\")\n",
    "                print(f\"Epoch number {i+1} done. MSE: {loss_avg} \\xB1 {loss_std}. \"\n",
    "                    f\"UQI: {uqi_loss_avg} \\xB1 {uqi_loss_std} \"\n",
    "                    f\"Elapsed time: {np.round(end-start, 2)}s. ETA: {np.round(eta, 2)}s\")\n",
    "            else:\n",
    "                print(f\"Epoch number {i+1} done. MSE: {loss_avg} \\xB1 {loss_std}. \"\n",
    "                    f\"Elapsed time: {np.round(end-start, 2)}s. ETA: {np.round(eta, 2)}s\")\n",
    "        if img_shape is not None:\n",
    "            print(f\"Total time spent on UQI computation: {np.round(tot_uqi_time, 2)}s\")\n",
    "    \n",
    "    def reconstruct(self, ts_data, seed = None):\n",
    "        sampled_data = self.sample_data(ts_data, seed=seed)\n",
    "\n",
    "        h_prob0 = sigmoid(np.dot(sampled_data, self._weights) + self._bh)\n",
    "        sampled_h0 = self.sample_data(h_prob0, seed=seed)\n",
    "        \n",
    "        recon_data_prob = sigmoid(np.dot(sampled_h0, self._weights.T) + self._bv)\n",
    "        return recon_data_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boltzmann_machine = RBM(v_units = tr_img_shape[1], h_units = 100, seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boltzmann_machine.reset()\n",
    "boltzmann_machine.fit(tr_images, max_epochs = 20, lr = 1, batchsize = 50, img_shape = (28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_test = boltzmann_machine.reconstruct(ts_images)\n",
    "reconstructed_test_reshaped = np.reshape(reconstructed_test, (reconstructed_test.shape[0], 28, 28))\n",
    "ts_images_reshaped = np.reshape(ts_images, (ts_images.shape[0], 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_avg = np.round(mse(ts_images, reconstructed_test), 4)\n",
    "loss_std = np.round(((ts_images - reconstructed_test)**2).std(), 4)\n",
    "uqi_loss_list = []\n",
    "\n",
    "for i in range(ts_images_reshaped.shape[0]):\n",
    "    uqi_loss_list.append(uqi(ts_images_reshaped[i], reconstructed_test_reshaped[i]))\n",
    "uqi_loss_avg = np.round(np.mean(uqi_loss_list), 4)\n",
    "uqi_loss_std = np.round(np.std(uqi_loss_list), 4)\n",
    "\n",
    "print(f\"MSE: {loss_avg} \\xB1 {loss_std}\\n\"\n",
    "      f\"UQI: {uqi_loss_avg} \\xB1 {uqi_loss_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2983\n",
    "print(uqi(ts_images_reshaped[index], reconstructed_test_reshaped[index]))\n",
    "show_img(ts_images_reshaped[index])\n",
    "show_img(reconstructed_test_reshaped[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_test = boltzmann_machine._weights\n",
    "w_test = np.reshape(w_test, (28, 28, w_test.shape[1]))\n",
    "show_img(w_test[:, :, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.ones((20, 3))\n",
    "lul = np.random.random(3)\n",
    "print(lul)\n",
    "print(test)\n",
    "print(test - lul)\n",
    "v = test - lul\n",
    "c = test - np.broadcast_to(lul, test.shape)\n",
    "print(v-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.random.random(10)\n",
    "print(np.random.binomial(1, p=test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISPR1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
