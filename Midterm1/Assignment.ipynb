{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm 1 Assignment 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Various Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(image: np.ndarray, gray: bool = True) -> None:\n",
    "    \"\"\"simple utility to show images with axes disabled\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        image to show\n",
    "    gray : bool, optional\n",
    "        if true show image in grayscale, by default True\n",
    "    \"\"\"\n",
    "    if gray:\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of necessary methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding for boundaries of image is handled by replicating the nearest element of the image by default. This can be changed to any type of padding supported by OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_filter_convolution(image: np.ndarray, filter: np.ndarray, padtype=cv2.BORDER_REPLICATE) -> np.ndarray:\n",
    "    \"\"\"function to convolve an image with a filter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        image to convolve\n",
    "    filter : np.ndarray\n",
    "        filter to convolve\n",
    "    padtype : _type_, optional\n",
    "        type of padding to use, by default cv2.BORDER_REPLICATE\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        result of convolution of image with filter\n",
    "    \"\"\"\n",
    "    x_size, y_size = image.shape\n",
    "    filter_size = filter.shape[0]\n",
    "    padding = filter_size//2\n",
    "    padded_image = cv2.copyMakeBorder(image, padding, padding, padding, padding, padtype)\n",
    "    filtered_img = np.zeros((x_size, y_size))\n",
    "\n",
    "    for x in range(x_size):\n",
    "        for y in range(y_size):\n",
    "            filtered_img[x, y] = (padded_image[x: x+filter_size, y:y+filter_size] * filter).sum()\n",
    "    return filtered_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Filter Implementation\n",
    "The filter is created with using a radius $r$ of $\\lceil 3 \\sigma \\rceil$. This gives a filter of size $(2r + 1)\\times(2r + 1)$. Both dimensions, being the same, are always odd, allowing easy convolution of the filter with an image.<br>\n",
    "This size was picked because the values of the filter become very small after that point, thus making it a good cutoff for a discrete approximation of a Gaussian filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(scale: float, size: int = None) -> np.ndarray:\n",
    "    \"\"\"function returning a gaussian filter at given scale\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale : float\n",
    "        scale to use for the gaussian filter\n",
    "    size : int, optional\n",
    "        size of filter, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        the gaussian filter at given scale and either given size or computed one\n",
    "    \"\"\"\n",
    "    #if size of the filter is not given, use ceiling of 3*scale as radius r, giving a filter of size (2*r + 1)x(2*r +1)\n",
    "    if size is None:\n",
    "        size = int(2 * np.ceil(3*scale)) + 1\n",
    "    v = np.arange((-size // 2) + 1, (size // 2) + 1)\n",
    "    x = v * np.ones((size, size))\n",
    "    y = x.T\n",
    "    filter = 1/(2*np.pi*scale**2) * np.exp(-(x*x + y*y)/(2*scale**2))\n",
    "    return filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoG Filter Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the size of the filter the same method as the Gaussian filter was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoG(scale: float, size:int = None) -> np.ndarray:\n",
    "    \"\"\"function returning a laplacian of gaussian filter at given scale\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale : float\n",
    "        scale to use for the gaussian filter\n",
    "    size : int, optional\n",
    "        size of filter, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        the LoG filter at given scale and either given size or computed one\n",
    "    \"\"\"\n",
    "    if size is None:\n",
    "        size = int(2 * np.ceil(3*scale)) + 1\n",
    "    v = np.arange((-size // 2) + 1, (size // 2) + 1)\n",
    "    x = v * np.ones((size, size))\n",
    "    y = x.T\n",
    "    gaussian = 1/(2*np.pi*scale**2) * np.exp(-(x*x + y*y)/(2*scale**2))\n",
    "    log_filter = ((x*x + y*y)/(scale**4) - 2/(scale**2))*gaussian\n",
    "    return log_filter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DoG Filter Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoG(scale: float, size:int = None, k=2) -> np.ndarray:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob Detection Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob_detector(image: np.ndarray, scales:list[int], threshold:float = 0.03) -> list[tuple[int, int, float]]:\n",
    "    \"\"\"function implementing a scale space blob detector\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        image to run blob detection on\n",
    "    scales : list[int]\n",
    "        list of scales to use\n",
    "    threshold : float, optional\n",
    "        a point that is a potential center of a blob must be greater than this value to be actually picked, by default 0.03\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[int, int, float]]\n",
    "        a list containing tuples where the first two elements are coordinates and the third is the scale at which that point was chosen.\n",
    "        Each tuple is the center of a blob at that scale\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    img_x, img_y = image.shape\n",
    "    for scale in scales:\n",
    "        filter = LoG(scale)\n",
    "        output = scale * scale * img_filter_convolution(image, filter)\n",
    "        output = output * output\n",
    "        output = cv2.copyMakeBorder(output, 1, 1, 1, 1, cv2.BORDER_CONSTANT, 0)\n",
    "        outputs.append(output)\n",
    "    outputs = np.asarray(outputs)\n",
    "    \n",
    "    centers = []\n",
    "    test_list = []\n",
    "    for x in range(1, img_x+1):\n",
    "        for y in range(1, img_y+1):\n",
    "            current_slice = outputs[:,x-1:x+2,y-1:y+2]\n",
    "            test_list.append(np.amax(current_slice))\n",
    "            if np.amax(current_slice) > threshold:\n",
    "                indices = np.unravel_index(np.argmax(current_slice), current_slice.shape)\n",
    "                if indices[1] == 1 and indices[2] == 1:\n",
    "                    centers.append((x, y, scales[indices[0]]))\n",
    "    return centers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for LoG filter and convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./MSRC_ObjCategImageDatabase_v1/3_22_s.bmp\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# image normalizion and moving to grayspace instead of RGB\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "show_img(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = gaussian_filter(5)\n",
    "blurred_img = img_filter_convolution(gray, gauss)\n",
    "show_img(gauss)\n",
    "show_img(blurred_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = LoG(5)\n",
    "laplacian_img = img_filter_convolution(gray, laplacian)\n",
    "\n",
    "show_img(laplacian)\n",
    "show_img(laplacian_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob detection on selected images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./MSRC_ObjCategImageDatabase_v1/3_22_s.bmp\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "outputs = []\n",
    "scales = [1, 5, 10, 15, 20, 30]\n",
    "results = blob_detector(gray, scales, 0.03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image)\n",
    "for x, y, scale in results:\n",
    "    c = plt.Circle((y, x), scale*np.sqrt(2), color=\"red\", linewidth = 1.5, fill=False)\n",
    "    ax.add_patch(c)\n",
    "ax.plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"/home/davide/uni/ISPR-Midterms/Midterm1/MSRC_ObjCategImageDatabase_v1/1_11_s.bmp\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run blob detection on the image at a given scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 5\n",
    "tmp = blob_detection(gray, scale)\n",
    "plt.imshow(tmp, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"/home/davide/uni/ISPR-Midterms/Midterm1/MSRC_ObjCategImageDatabase_v1/sunflowers.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "outputs = []\n",
    "scales = [1, 2]\n",
    "blob_detector(gray, scales)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ret, thresholded_output = cv2.threshold(outputs[0][0], 200, 255, cv2.THRESH_BINARY)\n",
    "thresholded_output = thresholded_output.astype(np.uint8)\n",
    "contours = cv2.findContours(thresholded_output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "\n",
    "plt.imshow(thresholded_output, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = []\n",
    "for output, scale in outputs:\n",
    "    ret, thresholded_output = cv2.threshold(output, 150, 255, cv2.THRESH_BINARY)\n",
    "    thresholded_output = thresholded_output.astype(np.uint8)\n",
    "    contours = cv2.findContours(thresholded_output,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    for i in contours:\n",
    "        M = cv2.moments(i)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            centers.append((cx, cy, scale))\n",
    "        # print(f\"x: {cx} y: {cy} scale: {scale}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image)\n",
    "for x, y, scale in centers:\n",
    "    c = plt.Circle((x, y), scale*np.sqrt(2), color=\"red\", linewidth = 1.5, fill=False)\n",
    "    ax.add_patch(c)\n",
    "# x, y = output.shape\n",
    "# for row in range(x):\n",
    "#     for column in range(y):\n",
    "#         if thresholded_output[row, column] != 0:\n",
    "#             c = plt.Circle((column, row), scale*np.sqrt(2), color=\"red\", linewidth = 0.5, fill=False)\n",
    "#             ax.add_patch(c)\n",
    "ax.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISPR1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d70428cb802d46b2c43ec30f1deb3d9860be8b4379734460defbf308ff892fa9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
