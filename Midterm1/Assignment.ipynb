{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm 1 Assignment 6 Davide Amadei"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Various Imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(image: np.ndarray, gray: bool = True, title: str = None) -> None:\n",
    "    \"\"\"simple utility to show images with axes disabled\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        image to show\n",
    "    gray : bool, optional\n",
    "        if true show image in grayscale, by default True\n",
    "    \"\"\"\n",
    "    if gray:\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of necessary methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding for boundaries of image is handled by replicating the nearest element of the image by default. This can be changed to any type of padding supported by OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_filter_convolution(image: np.ndarray, filter: np.ndarray, padtype=cv2.BORDER_REPLICATE) -> np.ndarray:\n",
    "    \"\"\"function to convolve an image with a filter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        image to convolve\n",
    "    filter : np.ndarray\n",
    "        filter to convolve\n",
    "    padtype : _type_, optional\n",
    "        type of padding to use, by default cv2.BORDER_REPLICATE\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        result of convolution of image with filter\n",
    "    \"\"\"\n",
    "    x_size, y_size = image.shape\n",
    "    filter_size = filter.shape[0]\n",
    "    padding = filter_size//2\n",
    "    padded_image = cv2.copyMakeBorder(image, padding, padding, padding, padding, padtype)\n",
    "    filtered_img = np.zeros((x_size, y_size))\n",
    "\n",
    "    for x in range(x_size):\n",
    "        for y in range(y_size):\n",
    "            filtered_img[x, y] = (padded_image[x: x+filter_size, y:y+filter_size] * filter).sum()\n",
    "    return filtered_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Filter Implementation\n",
    "The filter is created using a radius $r$ of $\\lceil 3 \\sigma \\rceil$. This gives a filter of size $(2r + 1)\\times(2r + 1)$. This size is always odd, allowing convolution of the filter with an image as it can be centered on each of its pixels.<br>\n",
    "This size was picked because the values of the filter become very small after that point, thus making it a good cutoff for a discrete approximation of a Gaussian filter.<br>\n",
    "Implementation of this filter was not required but it was useful for testing purposes and to later implement the LoG filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(scale: float, size: int = None) -> np.ndarray:\n",
    "    \"\"\"function returning a gaussian filter at given scale\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale : float\n",
    "        scale to use for the gaussian filter\n",
    "    size : int, optional\n",
    "        size of filter, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        the gaussian filter at given scale and either given size or computed one\n",
    "    \"\"\"\n",
    "    #if size of the filter is not given, use ceiling of 3*scale as radius r, giving a filter of size (2*r + 1)x(2*r +1)\n",
    "    if size is None:\n",
    "        size = int(2 * np.ceil(3*scale)) + 1\n",
    "    v = np.arange((-size // 2) + 1, (size // 2) + 1)\n",
    "    x = v * np.ones((size, size))\n",
    "    y = x.T\n",
    "    filter = 1/(2*np.pi*scale**2) * np.exp(-(x*x + y*y)/(2*scale**2))\n",
    "    return filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoG Filter Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the size of the filter the same method as the Gaussian filter was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoG(scale: float, size:int = None) -> np.ndarray:\n",
    "    \"\"\"function returning a laplacian of gaussian filter at given scale\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale : float\n",
    "        scale to use for the gaussian filter\n",
    "    size : int, optional\n",
    "        size of filter, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        the LoG filter at given scale and either given size or computed one\n",
    "    \"\"\"\n",
    "    if size is None:\n",
    "        size = int(2 * np.ceil(3*scale)) + 1\n",
    "    v = np.arange((-size // 2) + 1, (size // 2) + 1)\n",
    "    x = v * np.ones((size, size))\n",
    "    y = x.T\n",
    "    gaussian = 1/(2*np.pi*scale**2) * np.exp(-(x*x + y*y)/(2*scale**2))\n",
    "    log_filter = scale * scale * ((x*x + y*y)/(scale**4) - 2/(scale**2))*gaussian\n",
    "    return log_filter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob Detection Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detector works by first centering on each point of the image (thus requiring padding on boundaries). At each point it takes a $3 \\times 3$ slice of the image centered on that point, and it checks if the maximum response in that slice, across all considered scales, is over the threshold. <br>\n",
    "If it is, it checks if the maximum that was found is centered in the image slice, in which case it is added to the list of points that are considered centers of blobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob_detector(image: np.ndarray, base_scale:float = 1, k = 6, threshold:float = 0.03) -> list[tuple[int, int, float]]:\n",
    "    \"\"\"function implementing a scale space blob detector\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        image to run blob detection on\n",
    "    base_scale : float\n",
    "        base scale to use for blob detection\n",
    "    k : int\n",
    "        number of scales to use\n",
    "    threshold : float, optional\n",
    "        a point that is a potential center of a blob must be greater than this value to be actually picked, by default 0.03\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[int, int, float]]\n",
    "        a list containing tuples where the first two elements are coordinates and the third is the scale at which that point was chosen.\n",
    "        Each tuple is the center of a blob at that scale\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    \n",
    "    # multiply base scale by increasing powers of 2 to obtain a list of scales\n",
    "    scales = [base_scale*(2**i) for i in range(k)]\n",
    "    img_x, img_y = image.shape\n",
    "    for scale in scales:\n",
    "        filter = LoG(scale)\n",
    "        output = img_filter_convolution(image, filter)\n",
    "        # take square of response to find both dark and bright blobs\n",
    "        output = output * output\n",
    "        # padding for boundaries handling\n",
    "        output = cv2.copyMakeBorder(output, 1, 1, 1, 1, cv2.BORDER_CONSTANT, 0)\n",
    "        outputs.append(output)\n",
    "    outputs = np.asarray(outputs)\n",
    "    \n",
    "    centers = []\n",
    "    for x in range(1, img_x+1):\n",
    "        for y in range(1, img_y+1):\n",
    "            # take 3x3 slice on all scales\n",
    "            current_slice = outputs[:,x-1:x+2,y-1:y+2]\n",
    "\n",
    "            # check if max is over threshold\n",
    "            if np.amax(current_slice) > threshold:\n",
    "                # find index of max\n",
    "                indices = np.unravel_index(np.argmax(current_slice), current_slice.shape)\n",
    "\n",
    "                # check if max is in center of slice\n",
    "                if indices[1] == 1 and indices[2] == 1:\n",
    "                    centers.append((x, y, scales[indices[0]]))\n",
    "    return centers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple function to plot circles that represent blobs. The radius of each circle is $\\sqrt{2} \\sigma$ where $\\sigma$ is the scale of that blob. This radius was used because it gives the circle where a LoG of scale $\\sigma$ has maximum response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_blobs(image: np.ndarray, centers: list[tuple[int,int,float]], title: str = \"Plot of blobs\") -> None:\n",
    "    \"\"\"function to plot circles representing blobs based on the given list of center points\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        image to plot blobs on\n",
    "    centers : list[tuple[int,int,float]]\n",
    "        list of tuples of shape (x, y, scale) giving coordinates of a blob and its scale\n",
    "    title : str, optional\n",
    "        title of image to displat, by default \"Plot of blobs\"\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    for x, y, scale in centers:\n",
    "        c = plt.Circle((y, x), scale*np.sqrt(2), color=\"red\", linewidth = 1.5, fill=False)\n",
    "        ax.add_patch(c)\n",
    "    ax.plot()\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for LoG filter and convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./MSRC_ObjCategImageDatabase_v1/3_22_s.bmp\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# image normalizion and moving to grayspace instead of RGB\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "show_img(gray)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for the image convolution method using a gaussian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = gaussian_filter(5)\n",
    "blurred_img = img_filter_convolution(gray, gauss)\n",
    "\n",
    "show_img(gauss, title=\"Gaussian Filter\")\n",
    "show_img(blurred_img, title=\"Image convolved with Gaussian filter\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for the Laplacian of Gaussian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = LoG(5)\n",
    "laplacian_img = img_filter_convolution(gray, laplacian)\n",
    "\n",
    "show_img(laplacian, title=\"LoG filter\")\n",
    "show_img(laplacian_img, title=\"Image convolved with LoG filter\")\n",
    "show_img(laplacian_img*laplacian_img, title=\"Squared responses to LoG filter\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob detection on selected images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images were chosen as using the algorithm on them allows a good showcase of what the algorithm can do and its limitations. <br>\n",
    "We will use the same scales and the same threshold for all images but for better results it would be best to use different values for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold was picked by hand by checking results and seeing the blobs that are found and the range of values\n",
    "# obtained at each point by the blob detector\n",
    "threshold = 0.03\n",
    "\n",
    "base_scale = 2\n",
    "\n",
    "k = 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this image we can see one of the faults of the LoG blob detector. The wheel on the left is facing the camera, making it appear circular and thus the blob detector is able to pick it up. The one on the right, on the other hand, is slightly slanted, making it more of an ellipsoid, rendering the blob detector unable to detect it, as it only works with circular blobs.<br>\n",
    "The rest of the image has alright results, with the car windows being detected and the part of the car being split in various blobs. The smaller scales detect blobs in some random spots and there are some large blobs on the ground despite no apparent reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./images/image1.bmp\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# normalize image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "\n",
    "results = blob_detector(gray, base_scale=base_scale, k=k, threshold=threshold)\n",
    "print(results)\n",
    "plot_blobs(image, results, \"Blobs in image 1\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this image the blob detector works surprisingly well, and despite splitting the face in multiple blobs of varying sizes there are not many stray blobs, as it should be, given the rest of the image is generally uniform in color. Weirdly enough, only one eye is detected even though both are front facing.<br>\n",
    "The largest scale space is even somewhat able to detect the whole face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./images/image2.bmp\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# normalize image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "\n",
    "results = blob_detector(gray, base_scale=base_scale, k=k, threshold=threshold)\n",
    "plot_blobs(image, results, \"Blobs in image 1\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most \"correct\" thing that is detected in this image are the windows of the building. The larger scale spaces are also splitting the building in multiple blobs, to a degree, but it is not particularly precise.<br>\n",
    "Interestingly, the holes left by the leaves of the trees are picked up as blobs, as they are after all a brighter circle on a dark background, leading to a high response when a LoG filter is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./images/image3.bmp\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# normalize image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "\n",
    "results = blob_detector(gray, base_scale=base_scale, k=k, threshold=threshold)\n",
    "plot_blobs(image, results, \"Blobs in image 1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this image the cows are correctly (given the limitations of the algorithm) detected as compositions of blobs. The roof in the background is also detected as multiple blobs probably because of how bright it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./images/image4.bmp\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# normalize image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "\n",
    "results = blob_detector(gray, base_scale=base_scale, k=k, threshold=threshold)\n",
    "plot_blobs(image, results, \"Blobs in image 1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the cows closer together the algorithm works a lot worse as the boundaries between each other are much less clear, leading to the algorithm only detecting the white spots on their body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./images/image5.bmp\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# normalize image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "\n",
    "results = blob_detector(gray, base_scale=base_scale, k=k, threshold=threshold)\n",
    "plot_blobs(image, results, \"Blobs in image 1\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Image\n",
    "Image outside of the given dataset to show an example where blob detector works decently and picks up everything you would expect, both dark blobs (e.g. the center of the sunflowers) and bright blobs (e.g. the sun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./images/extra.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# normalize image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "\n",
    "results = blob_detector(gray, base_scale=base_scale, k=k, threshold=threshold)\n",
    "plot_blobs(image, results, \"Blobs in image 1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks\n",
    "\n",
    "I picked this assignment as in general implementing stuff from scratch allows me to better understand how a topic works. This held true in this case as well. In particular I was unsure of how to actually select the blobs after running the convolution, and it is a lot clearer now.<br>\n",
    "On this subject, while it works as it is currently, there is probably a large margin of improvement on that front, as in each window it only checks for a single maximum value across all scale. It might be useful to do a finer search to keep potentially good points.<br><br>\n",
    "\n",
    "The code is also quite slow, using DoG instead of LoG would likely be a nice speedup and if done smartly could also lead to better efficiency in terms of space.<br><br>\n",
    "\n",
    "In general the analysis could be improved by trying more scales and varying thresholds, but the results obtained on the images are already acceptable, as in each image it detects what one could generally think of as a circular blob. Of course using LoG for blob detection has limits and they can be seen even in these small examples. <br>\n",
    "The biggest issues can be seen in images 1 and 5, as described in their respective sections, but all images aside from image 2 have a lot of \"noise\", with a lot of blobs in seemingly random locations. These blobs are more frequent at small scale spaces, which is not too surprising.<br>\n",
    "Another variable that could maybe change results in some cases is also how padding is handled at image boundaries, and it could be useful to try the different ways to check if one leads to better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISPR1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d70428cb802d46b2c43ec30f1deb3d9860be8b4379734460defbf308ff892fa9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
